{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "380e3f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U albumentations\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import random\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "mp_face_detection = mp.solutions.face_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5c0e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvat labels to kitti txt files\n",
    "\n",
    "# import xml.etree.ElementTree as ET\n",
    "# import os\n",
    "# import sys\n",
    "# import shutil\n",
    "# import cv2\n",
    "\n",
    "# cvat_xml_file = \"/data2/dsm-1507/dataset/Combined_csv/new_data/annotations_dec21.xml\"\n",
    "\n",
    "# kitti_annots_dest_path = \"/data2/dsm-1507/dataset/Combined_csv/new_data/21_Dec_anno/\"\n",
    "\n",
    "\n",
    "# tree = ET.parse(cvat_xml_file)\n",
    "\n",
    "# root = tree.getroot()\n",
    "\n",
    "# for node in root.iter('image'):\n",
    "\n",
    "#     image_dict = node.attrib\n",
    "\n",
    "#     zero_annots = True\n",
    "\n",
    "#     for elem in node.iter('box'):\n",
    "#         bbox_dict = elem.attrib\n",
    "#         if len(bbox_dict) != 0:\n",
    "#             zero_annots =  False\n",
    "#             break\n",
    "\n",
    "#     if zero_annots==True:\n",
    "#         continue\n",
    "\n",
    "#     file_name = os.path.basename(image_dict[\"name\"])\n",
    "\n",
    "#     f = open(kitti_annots_dest_path + os.path.splitext(file_name)[0] + \".txt\", \"w\")\n",
    "\n",
    "#     for elem in node.iter('box'):\n",
    "#         bbox_dict = elem.attrib\n",
    "#         f.write(\"{0} 0.00 0 0.00 {1:.2f} {2:.2f} {3:.2f} {4:.2f} 0.00 0.00 0.00 0.00 0.00 0.00 0.00\\n\".format(bbox_dict[\"label\"].lower(),float(bbox_dict[\"xtl\"]),float(bbox_dict[\"ytl\"]),float(bbox_dict[\"xbr\"]),float(bbox_dict[\"ybr\"])))\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "77cff314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_imgs_dir = '/data2/dsm-1507/dataset/Augmented_cellphone_cig/original_imgs_and_annos/smoking/smoking_3800'\n",
    "# src_annots_dir  = '/data2/dsm-1507/dataset/Augmented_cellphone_cig/original_imgs_and_annos/smoking/original_annos'\n",
    "\n",
    "\n",
    "# src_imgs_dir = '/data2/dsm-1507/dataset/Augmented_cellphone_cig/original_imgs_and_annos/cellphone/Cell_Phone_download'\n",
    "# src_annots_dir  = '/data2/dsm-1507/dataset/Augmented_cellphone_cig/original_imgs_and_annos/cellphone/original_annos'\n",
    "\n",
    "\n",
    "# src_imgs_dir = '/data2/dsm-1507/dataset/Combined_csv/new_data/21_Dec'\n",
    "# src_annots_dir  = '/data2/dsm-1507/dataset/Combined_csv/new_data/21_Dec_anno'\n",
    "\n",
    "\n",
    "# src_imgs_dir = '/data2/dsm-1507/dataset/Combined_csv/new_data/cellphone_new'\n",
    "# src_annots_dir  = '/data2/dsm-1507/dataset/Combined_csv/new_data/cellphone_anno'\n",
    "\n",
    "\n",
    "# src_imgs_dir = '/data2/dsm-1507/dataset/Combined_csv/new_data/cellphone_new_1_imgs'\n",
    "# src_annots_dir  = '/data2/dsm-1507/dataset/Combined_csv/new_data/cellphone_new_1_anno'\n",
    "\n",
    "\n",
    "# src_imgs_dir = '/data2/dsm-1507/dataset/Combined_csv/new_data/cig_new'\n",
    "# src_annots_dir  = '/data2/dsm-1507/dataset/Combined_csv/new_data/cig_anno'\n",
    "\n",
    "\n",
    "src_imgs_dir = '/data2/dsm-1507/dataset/Combined_csv/new_data/images_instagram_smoking'\n",
    "src_annots_dir  = '/data2/dsm-1507/dataset/Combined_csv/new_data/images_instagram_smoking_anno'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b1a3db60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_annots_dir  = \"/data2/dsm-1507/dataset/Combined_csv/new_data/cig_anno\"\n",
    "# src_imgs_dir    = '/data2/dsm-1507/dataset/Combined_csv/new_data/cig_new'\n",
    "\n",
    "dest_annots_dir =\"/data2/dsm-1507/dataset/Combined_csv/single_aug/a\"\n",
    "dest_imgs_dir   = \"/data2/dsm-1507/dataset/Combined_csv/single_aug/i\"\n",
    "# \n",
    "\n",
    "# dest_annots_dir =\"/data2/dsm-1507/dataset/Combined_csv/with_face_annots/a_x\"\n",
    "# dest_imgs_dir   = \"/data2/dsm-1507/dataset/Combined_csv/with_face_annots/i_x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6eeb6220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add face dets to annots\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "anno_path = [os.path.join(src_annots_dir,x) for x in os.listdir(src_annots_dir)]\n",
    "image_path = []\n",
    "anno_path\n",
    "\n",
    "for path in tqdm(anno_path):\n",
    "    basename = os.path.basename(path)\n",
    "#     print(basename)\n",
    "    if os.path.exists((os.path.join(src_imgs_dir,f'{basename[:-4]}.jpg'))):\n",
    "        im_p = f'{basename[:-4]}.jpg'\n",
    "    elif os.path.exists((os.path.join(src_imgs_dir,f'{basename[:-4]}.jpg'))):\n",
    "        im_p = f'{basename[:-4]}.jpg'\n",
    "    elif os.path.exists((os.path.join(src_imgs_dir,f'{basename[:-4]}.jpeg'))):\n",
    "        im_p = f'{basename[:-4]}.jpeg'\n",
    "        \n",
    "    if os.path.exists(os.path.join(src_imgs_dir,im_p)) is False:\n",
    "        continue\n",
    "    \n",
    "    image_path.append(os.path.join(src_imgs_dir,im_p))\n",
    "    \n",
    "                     \n",
    "# def face_crop_from_img(mp_face_detection,image,min_detection_confidence=0.55,prop = 1.5):\n",
    "for i in tqdm(range(len(anno_path))):\n",
    "    img = cv2.imread(image_path[i])\n",
    "#     print(img.shape)\n",
    "\n",
    "\n",
    "    face_loc = face_crop_from_img(mp_face_detection,img,min_detection_confidence=0.55,prop = 0.5)\n",
    "#     print(face_loc)\n",
    "    if face_loc is not None:\n",
    "        f = open(anno_path[i], \"a\")\n",
    "        f.write(\"{0} 0.00 0 0.00 {1:.2f} {2:.2f} {3:.2f} {4:.2f} 0.00 0.00 0.00 0.00 0.00 0.00 0.00\\n\".format('face',\n",
    "                                                                                                              face_loc[0][0],\n",
    "                                                                                                              face_loc[0][1],\n",
    "                                                                                                              face_loc[1][0],\n",
    "                                                                                                              face_loc[1][1]))\n",
    "\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5dbd90f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_crop_from_img(mp_face_detection,image,min_detection_confidence=0.55,prop = 1.5):\n",
    "    def adjest_points(n,w,h):\n",
    "            if n[0]<0:\n",
    "                n[0]=0\n",
    "            if n[1]<0:\n",
    "                n[1]=0\n",
    "\n",
    "            if n[0]>w:\n",
    "                n[0]=w\n",
    "            if n[1]>h:\n",
    "                n[1]=h\n",
    "\n",
    "            return([int(n[0]),int(n[1])])\n",
    "    \n",
    "    with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=min_detection_confidence) as face_detection:\n",
    "        if type(image) == str:\n",
    "            img = cv2.imread(image)\n",
    "            h, w = img.shape[:2]\n",
    "        else:\n",
    "            img = image\n",
    "            h, w = img.shape[:2]\n",
    "        # Convert the BGR image to RGB and process it with MediaPipe Face Detection.\n",
    "        results = face_detection.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Draw face detections of each face.\n",
    "        if not results.detections:\n",
    "            return None\n",
    "\n",
    "        for detection in results.detections:\n",
    "            # NOSE_TIP = mp_face_detection.get_key_point(detection, mp_face_detection.FaceKeyPoint.NOSE_TIP)\n",
    "            # n = (int(NOSE_TIP.x*w),int(NOSE_TIP.y*h))\n",
    "\n",
    "            # MOUTH_CENTER = mp_face_detection.get_key_point(detection, mp_face_detection.FaceKeyPoint.MOUTH_CENTER)\n",
    "            # m = (int(MOUTH_CENTER.x*w),int(MOUTH_CENTER.y*h))\n",
    "\n",
    "            x = int(detection.location_data.relative_bounding_box.xmin*w)\n",
    "            y = int(detection.location_data.relative_bounding_box.ymin*h)\n",
    "            x1 = int((detection.location_data.relative_bounding_box.xmin+detection.location_data.relative_bounding_box.width)*w)\n",
    "            y1 = int((detection.location_data.relative_bounding_box.ymin+detection.location_data.relative_bounding_box.height)*h)\n",
    "\n",
    "            x,y = adjest_points([x,y],w,h)\n",
    "            x1,y1 = adjest_points([x1,y1],w,h)\n",
    "            #print(x,y,x1,y1)\n",
    "            \n",
    "            ox = (x+x1)*0.5\n",
    "            oy = (y+y1)*0.5\n",
    "            \n",
    "            \n",
    "            fx = ox - (x1-x)*prop\n",
    "            fy = oy - (y1-y)*prop\n",
    "            fx1 = ox + (x1-x)*prop\n",
    "            fy1 = oy + (y1-y)*prop\n",
    "            \n",
    "            a = adjest_points([fx,fy],w,h)\n",
    "            b = adjest_points([fx1,fy1],w,h)\n",
    "            \n",
    "        cropped = img[a[1]:b[1],a[0]:b[0]]\n",
    "        data = a,b\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1ae433dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annos_from_txt(src_annots_dir,annotation_file):\n",
    "    with open(os.path.join(src_annots_dir,annotation_file), \"r\") as ins:\n",
    "        lines = [line.rstrip('\\n') for line in ins]\n",
    "        \n",
    "        if lines==0:\n",
    "            return None\n",
    "\n",
    "        data = []\n",
    "        for line in lines:\n",
    "            coordinates = line.split()\n",
    "            bbox = [coordinates[0],float(coordinates[4]),float(coordinates[5]),float(coordinates[6]),float(coordinates[7])]\n",
    "            data.append(bbox)\n",
    "        # f = open(dest_annots_dir + annotation_file, \"w\")   \n",
    "        # \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dad8945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def x1y1x2y2_to_xywh(bbox_list):\n",
    "    x1 = bbox_list[0]\n",
    "    y1 = bbox_list[1]\n",
    "    x2 = bbox_list[2]\n",
    "    y2 = bbox_list[3]\n",
    "    \n",
    "    w = x2-x1\n",
    "    h = y2-y1\n",
    "    \n",
    "    return [int(x1),int(y1),int(w),int(h)]\n",
    "\n",
    "def xywh_to_x1y1x2y2(bbox_list):\n",
    "    x1 = bbox_list[0]\n",
    "    y1 = bbox_list[1]\n",
    "    w = bbox_list[2]\n",
    "    h = bbox_list[3]\n",
    "    \n",
    "    x2 = x1+w\n",
    "    y2 = y1+h\n",
    "    \n",
    "    return [int(x1),int(y1),int(x2),int(y2)]\n",
    "\n",
    "def aug_im_box(image,bbox_list,transform):\n",
    "    \n",
    "    transformed = transform(image=image, bboxes=bbox_list)\n",
    "    transformed_image = transformed['image']\n",
    "    transformed_bboxes = transformed['bboxes']\n",
    "    \n",
    "    return transformed_image,transformed_bboxes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f911ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "34865782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 4262/4262 [03:45<00:00, 18.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19033 lllllll\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "src_annots = sorted(os.listdir(src_annots_dir)) \n",
    "DO_AUG = True\n",
    "ii = 15208 # no by which image is saved\n",
    "no_aug = 5 # no of times the same image is augmented\n",
    "for annotation_file in tqdm(src_annots):    \n",
    "#     if ii>= 85669+100:\n",
    "#         break\n",
    "\n",
    "    try:\n",
    "        \n",
    "        for _ in range(no_aug):\n",
    "            image_name = os.path.join(src_imgs_dir, os.path.basename(annotation_file)[:-3])\n",
    "#             print('kk',image_name)\n",
    "            if os.path.exists(image_name + \"jpg\"):\n",
    "                image_name += \"jpg\"\n",
    "            elif os.path.exists(image_name + \"jpeg\"):\n",
    "                image_name += \"jpeg\"\n",
    "\n",
    "            elif os.path.exists(image_name + \"png\"):\n",
    "                image_name += \"png\"\n",
    "\n",
    "            if os.path.exists(image_name) is False:\n",
    "#                 print('image_name is False',ii)\n",
    "                \n",
    "                continue\n",
    "            \n",
    "            img = cv2.imread(image_name)\n",
    "           \n",
    "            \n",
    "\n",
    "\n",
    "            anno_data = get_annos_from_txt(src_annots_dir,annotation_file)\n",
    "            if anno_data is None:\n",
    "#                 print('anno_data is None',ii)\n",
    "                continue\n",
    "#             print(face_data,anno_data,annotation_file)\n",
    "\n",
    "            bbox_list = []\n",
    "            for data in anno_data:\n",
    "                x = []\n",
    "\n",
    "                x.append(int(data[1]))\n",
    "                x.append(int(data[2]))\n",
    "                x.append(int(data[3]))\n",
    "                x.append(int(data[4]))\n",
    "                x = x1y1x2y2_to_xywh(x)\n",
    "\n",
    "                x.append(data[0])\n",
    "                bbox_list.append(x)\n",
    "\n",
    "            transform = A.Compose([\n",
    "                A.HorizontalFlip(p=0.0000001),\n",
    "#                 A.RandomBrightnessContrast(p=0.2),\n",
    "#                 A.Affine(p=0.5),\n",
    "#                 A.RandomBrightnessContrast(p=0.2),\n",
    "#                 A.CLAHE(),\n",
    "#                 A.RGBShift(),\n",
    "#                 A.ImageCompression(),\n",
    "#                 A.GaussNoise(),\n",
    "#                 A.RandomScale(),\n",
    "                ], bbox_params=A.BboxParams(format='coco'))\n",
    "\n",
    "            transformed_img, transformed_bbox = aug_im_box(img,bbox_list,transform)\n",
    "\n",
    "            bbox_data = []\n",
    "            for data in transformed_bbox :\n",
    "\n",
    "                d = []\n",
    "                d.append(data[-1])\n",
    "                for x in xywh_to_x1y1x2y2(data[:-1]):\n",
    "                    d.append(x)\n",
    "                bbox_data.append(d)\n",
    "\n",
    "\n",
    "            face_data = face_crop_from_img(mp_face_detection,transformed_img,min_detection_confidence=0.55,prop = 1.2)\n",
    "            if face_data is None:\n",
    "#                 print('face_data is None',ii)\n",
    "                continue\n",
    "\n",
    "            x1_list = []\n",
    "            x1_list.append(face_data[0][0])\n",
    "            for data in bbox_data:\n",
    "                x1_list.append(data[1])\n",
    "\n",
    "            y1_list = []\n",
    "            y1_list.append(face_data[0][1])\n",
    "            for data in bbox_data:\n",
    "                y1_list.append(data[2])\n",
    "\n",
    "            x2_list = []\n",
    "            x2_list.append(face_data[1][0])\n",
    "            for data in bbox_data:\n",
    "                x2_list.append(data[3])\n",
    "\n",
    "            y2_list = []\n",
    "            y2_list.append(face_data[1][1])\n",
    "            for data in bbox_data:\n",
    "                y2_list.append(data[4])\n",
    "\n",
    "            crop_cordi = [min(x1_list),min(y1_list),max(x2_list),max(y2_list)]\n",
    "\n",
    "            scaled_annos = []\n",
    "            for data in bbox_data:\n",
    "                if data[0] != 'face':\n",
    "                    x = []\n",
    "                    x.append(data[0])\n",
    "                    x.append(int(data[1]-crop_cordi[0]))\n",
    "                    x.append(int(data[2]-crop_cordi[1]))\n",
    "                    x.append(int(data[3]-crop_cordi[0]))\n",
    "                    x.append(int(data[4]-crop_cordi[1]))\n",
    "                    scaled_annos.append(x)\n",
    "\n",
    "            a,b = face_data\n",
    "            face_crp_img = transformed_img[a[1]:b[1],a[0]:b[0]].copy()\n",
    "\n",
    "\n",
    "\n",
    "    #         print(bbox_data)\n",
    "\n",
    "\n",
    "    #         for data in scaled_annos:\n",
    "    #             img = cv2.rectangle(face_crp_img,(data[1],data[2]),(data[3],data[4]),(0,0,200), 1)\n",
    "            ii+=1\n",
    "            out_im_name = f'{dest_imgs_dir}/{ii}.jpg'\n",
    "#             print(out_im_name)\n",
    "            cv2.imwrite(out_im_name,face_crp_img)\n",
    "\n",
    "            f = open(f'{dest_annots_dir}/{ii}.txt', \"w\")\n",
    "            if DO_AUG is False:\n",
    "                scaled_annos = anno_data\n",
    "            for data in scaled_annos:\n",
    "                if data[0] != 'face':\n",
    "                    f.write(\"{0} 0.00 0 0.00 {1:.2f} {2:.2f} {3:.2f} {4:.2f} 0.00 0.00 0.00 0.00 0.00 0.00 0.00\\n\".format(data[0],\n",
    "                                                                                                                  data[1],\n",
    "                                                                                                                  data[2],\n",
    "                                                                                                                  data[3],\n",
    "                                                                                                                  data[4]))\n",
    "            f.close()\n",
    "            \n",
    "    except:pass        \n",
    "print(ii,'lllllll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc20d853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3806\n"
     ]
    }
   ],
   "source": [
    "# Ramdomly sample images for validation set\n",
    "from random import sample\n",
    "path = '/data2/dsm-1507/dataset/Combined_csv/single_aug/aug_anno'\n",
    "annos_path_list = os.listdir(path)\n",
    "\n",
    "src = '/data2/dsm-1507/dataset/Combined_csv/single_aug/aug_anno'\n",
    "dst = '/data2/dsm-1507/dataset/Combined_csv/single_aug/aug_anno_val'\n",
    "\n",
    "x = sample(annos_path_list,(int(len(annos_path_list)*0.2)))\n",
    "\n",
    "\n",
    "for file in x:\n",
    "    os.rename(os.path.join(src,file), os.path.join(dst,file))\n",
    "\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cf5e6523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 23017/23017 [03:24<00:00, 112.60it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# convert rgb image to rrr image\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "src_path = '/data2/dsm-1507/dataset/Combined_csv/single_aug/aug_imgs'\n",
    "dst_path = '/data2/dsm-1507/dataset/Combined_csv/single_aug/aug_imgs_rrr'\n",
    "# /media/cheling/dataset2/dsm-1507/dataset/\n",
    "\n",
    "for filename in tqdm(os.listdir(src_path)):\n",
    "    image_path = os.path.join(src_path,filename)\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    r_im = img[:,:,2] #ir_img\n",
    "    rrr_im = np.stack((r_im,)*3, axis=-1)#ir_img\n",
    "    \n",
    "    cv2.imwrite(f'{dst_path}/{filename[:-4]}.jpg',rrr_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2bd61af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create csv file to train effidet models\n",
    "import os\n",
    "import sys\n",
    "import imagesize\n",
    "from tqdm import tqdm\n",
    "# /media/cheling/dataset2/dsm-1507/dataset/Combined_csv/with_face_annots/aug_annos_val\n",
    "\n",
    "f = open(\"/data2/dsm-1507/dataset/Combined_csv/single_aug/cig_hand_cellphone_jan5.csv\",\"w\")\n",
    "\n",
    "annotations_dir = '/data2/dsm-1507/dataset/Combined_csv/single_aug/aug_anno/'\n",
    "val_annotations_dir = '/data2/dsm-1507/dataset/Combined_csv/single_aug/aug_anno_val/'\n",
    "x = sorted(os.listdir(annotations_dir))\n",
    "y = sorted(os.listdir(val_annotations_dir))\n",
    "\n",
    "from tqdm import tqdm\n",
    "for annotation_file in (x):\n",
    "    image_name = '/data2/dsm-1507/dataset/Combined_csv/single_aug/aug_imgs/'+os.path.basename(annotation_file)[:-4] + '.jpg'\n",
    "    with open(annotations_dir+annotation_file, \"r\") as ins:\n",
    "            lines = [line.rstrip('\\n') for line in open(annotations_dir+annotation_file)]\n",
    "            if lines==0:\n",
    "                continue\n",
    "            width, height = imagesize.get(image_name)\n",
    "            \n",
    "            for line in lines:\n",
    "                f.write(\"TRAIN,\"+image_name)\n",
    "                coordinates = line.split()\n",
    "                bbox = [coordinates[0],int(float(coordinates[4])),int(float(coordinates[5])),int(float(coordinates[6])),int(float(coordinates[7]))]\n",
    "                rect = [ bbox[1]/(width*1.0), bbox[2]/(height*1.0), bbox[3]/(width*1.0), bbox[4]/(height*1.0)]\n",
    "                f.write(\",{0},{1:.2f},{2:.2f},,,{3:.2f},{4:.2f},,\\n\".format(bbox[0],rect[0],rect[1],rect[2],rect[3]))\n",
    "\n",
    "for annotation_file in y:\n",
    "    #image_name = '/data2/dsm-training-1908/images_new_roi_gray_jpg/'+os.path.basename(annotation_file)[:-4] + '_gray.jpg'\n",
    "    image_name = '/data2/dsm-1507/dataset/Combined_csv/single_aug/aug_imgs/'+os.path.basename(annotation_file)[:-4] + '.jpg'\n",
    "    with open(val_annotations_dir+annotation_file, \"r\") as ins:\n",
    "            lines = [line.rstrip('\\n') for line in open(val_annotations_dir+annotation_file)]\n",
    "            if lines==0:\n",
    "                continue\n",
    "            width, height = imagesize.get(image_name)\n",
    "            for line in lines:\n",
    "                f.write(\"VALIDATION,\"+image_name)\n",
    "                coordinates = line.split()\n",
    "                bbox = [coordinates[0],int(float(coordinates[4])),int(float(coordinates[5])),int(float(coordinates[6])),int(float(coordinates[7]))]\n",
    "                rect = [ bbox[1]/(width*1.0), bbox[2]/(height*1.0), bbox[3]/(width*1.0), bbox[4]/(height*1.0)]\n",
    "                f.write(\",{0},{1:.2f},{2:.2f},,,{3:.2f},{4:.2f},,\\n\".format(bbox[0],rect[0],rect[1],rect[2],rect[3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
